{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96dc8464-fa68-4c14-a8d1-d92269cb6aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import collections\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from time import perf_counter\n",
    "from io import StringIO\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f94ad3-be4b-43a4-8bfc-6bc3b7927ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use to measure execution of a given block of code:\n",
    "# with catchtime():\n",
    "#   # code here\n",
    "class catchtime:\n",
    "    def __enter__(self):\n",
    "        self.start = perf_counter()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        self.time = perf_counter() - self.start\n",
    "        self.readout = f'Time: {self.time:.3f} seconds'\n",
    "        print(self.readout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c5587f3-db0f-4695-ae4f-939238f2db85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c5ba025-9b3f-42ce-81e6-5147d74f102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "with open(\"jp_en_sentences.tsv\", 'r', encoding='utf-8-sig') as f:\n",
    "    raw = f.read()\n",
    "    raw = raw.replace(\"”\", \"\\\"\")\n",
    "    raw = raw.replace(\"“\", \"\\\"\")\n",
    "    rd = csv.DictReader(StringIO(raw), delimiter=\"\\t\")\n",
    "    for row in rd:\n",
    "        sentences.append((row['jp'], row['en']))\n",
    "jp = [jp for jp, _ in sentences]\n",
    "en = [en for _, en in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f6b844-fb3b-4c52-b49e-6c2e57978404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num sentence pairs:  264482\n"
     ]
    }
   ],
   "source": [
    "print(\"num sentence pairs: \", len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417ce9da-bef3-49a1-852d-d83c6d069b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 520\n",
    "BOS = \"BOS\"\n",
    "EOS = \"EOS\"\n",
    "jp_chars = sorted(list(set(\"\".join([jp for jp, en in sentences]))))\n",
    "jp_vocab_size = len(jp_chars)\n",
    "jp_stoi = { ch:i for i,ch in enumerate(jp_chars) }\n",
    "jp_stoi[EOS] = len(jp_stoi)\n",
    "jp_stoi[BOS] = len(jp_stoi)\n",
    "jp_itos = { i:ch for i,ch in enumerate(jp_chars) }\n",
    "jp_itos[len(jp_stoi)-2] = EOS\n",
    "jp_itos[len(jp_stoi)-1] = BOS\n",
    "\n",
    "JP_VOCAB_SIZE = len(jp_stoi)\n",
    "\n",
    "\n",
    "def encode_jp(sent):\n",
    "    enc = [jp_stoi[BOS]] + [jp_stoi[c] for i, c in enumerate(sent)]\n",
    "    enc += [jp_stoi[EOS]] * (block_size - len(enc))\n",
    "    return enc\n",
    "def decode_jp(encoded):\n",
    "    return \"\".join([jp_itos[c] for c in encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aac57054-fc8f-4808-bcf9-e0e214ee2e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BOSきみにちょっとしたものをもってきたよ。EOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOSEOS'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_jp(encode_jp(sentences[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b353aed4-33ee-4457-95f8-7981821dbd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkedListIter:\n",
    "    def __init__(self, head):\n",
    "        self.head = head\n",
    "    def __next__(self):\n",
    "        if not self.head:\n",
    "            raise StopIteration\n",
    "        curr = self.head\n",
    "        self.head = self.head.next\n",
    "        return curr\n",
    "\n",
    "class LinkedList:\n",
    "    def __init__(self, contents):\n",
    "        self.contents = contents\n",
    "        self.next = None\n",
    "        self.cached_full = None\n",
    "\n",
    "    @staticmethod\n",
    "    def create(chunk):\n",
    "        curr = None\n",
    "        head = None\n",
    "        for c in chunk:\n",
    "            new = LinkedList(c)\n",
    "            if curr:\n",
    "                curr.next = new\n",
    "            else:\n",
    "                head = new\n",
    "            curr = new\n",
    "        head.cached_full = chunk\n",
    "        return head\n",
    "    def merge(self):\n",
    "        assert self.next\n",
    "        self.contents += self.next.contents\n",
    "        self.next = self.next.next\n",
    "\n",
    "    def __iter__(self):\n",
    "        return LinkedListIter(self)\n",
    "    def __repr__(self):\n",
    "        return f\"LL{{{self.contents}, {self.next}}}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5ddc08b-2ad0-4417-a518-df7a0f6107e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_bigrams(chunks, weights):\n",
    "    counter = collections.Counter()\n",
    "    for chunk_i in range(len(chunks)):\n",
    "        chunk = chunks[chunk_i]\n",
    "        if not chunk.next:\n",
    "            continue\n",
    "        for c1, c2 in zip(chunk, chunk.next):\n",
    "            counter[(c1.contents, c2.contents)] += weights[chunk.cached_full]\n",
    "    return counter            \n",
    "        \n",
    "def merge(chunks, bigram, cnts, weights):\n",
    "    cnts[bigram] = 0\n",
    "    for chunk in chunks:\n",
    "        head = chunk\n",
    "        prev = None\n",
    "        while head:\n",
    "            if not head.next:\n",
    "                break\n",
    "            c1, c2 = head.contents, head.next.contents\n",
    "            if (c1, c2) == bigram:\n",
    "                head.merge()\n",
    "                if prev:\n",
    "                    cnts[(prev.contents, head.contents)] += weights[chunk.cached_full]\n",
    "                if head.next:\n",
    "                    cnts[(head.contents, head.next.contents)] += weights[chunk.cached_full]\n",
    "            prev = head\n",
    "            head = head.next\n",
    "\n",
    "def seed_merges(sentences):\n",
    "    out = {}\n",
    "    for sent in sentences:\n",
    "        for c in sent:\n",
    "            if c not in out:\n",
    "                out[c] = len(out)\n",
    "    return out\n",
    "\n",
    "def count_occurences(splits):\n",
    "    counter = collections.Counter()\n",
    "    for sent in splits:\n",
    "        for chunk in sent:\n",
    "            counter[chunk] += 1\n",
    "    return counter\n",
    "\n",
    "PRE_TOKENIZATION_REGEX = re.compile(r\"'s|'t|'re|'ve|'m|'ll|'d| ?\\w+|\\s|\\S\")\n",
    "\n",
    "def bpe(merges, sentences, vocab_size):\n",
    "    splits = [re.findall(PRE_TOKENIZATION_REGEX, s) for s in sentences]\n",
    "    weights = count_occurences(splits)\n",
    "    chunks = list(weights.keys())\n",
    "    for i in range(len(chunks)):\n",
    "        chunks[i] = LinkedList.create(chunks[i])\n",
    "    cnts = count_bigrams(chunks, weights)\n",
    "    for merge_id in range(vocab_size):\n",
    "        top = cnts.most_common(1)\n",
    "        if len(top) == 0:\n",
    "            return merges\n",
    "        top = top[0][0]\n",
    "        merges[\"\".join(top)] = len(merges)\n",
    "        merge(chunks, top, cnts, weights)\n",
    "    merges[EOS] = len(merges)\n",
    "    merges[BOS] = len(merges)\n",
    "    return merges\n",
    "\n",
    "def encode_en(sent, merges):\n",
    "    chunks = re.findall(PRE_TOKENIZATION_REGEX, sent)\n",
    "    for i in range(len(chunks)):\n",
    "        chunks[i] = LinkedList.create(chunks[i])\n",
    "    out = []\n",
    "    for chunk in chunks:\n",
    "        head = chunk\n",
    "        while head:\n",
    "            if not head.next:\n",
    "                break\n",
    "            c1, c2 = head.contents, head.next.contents\n",
    "            if (c1 + c2) in merges:\n",
    "                head.merge()\n",
    "            head = head.next\n",
    "    out = []\n",
    "    for chunk in chunks:\n",
    "        for c in chunk:\n",
    "            out.append(merges[c.contents])\n",
    "    out = [merges[BOS]] + out\n",
    "    out += [merges[EOS]] * (block_size - len(out))\n",
    "    return out\n",
    "\n",
    "def decode_en(enc, merges_reversed):\n",
    "    return \"\".join(merges_reversed[id] for id in enc)\n",
    "\n",
    "def print_encoded_chunks(encoded, merges_reversed):\n",
    "    \",\".join(rev[id] for id in enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dc2ddef-8987-4342-8cc5-23c4728a8fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre BPE size: 147\n",
      "Time: 10.982 seconds\n",
      "Dict size: 1149\n"
     ]
    }
   ],
   "source": [
    "CNT = len(sentences)\n",
    "with catchtime():\n",
    "    merges = seed_merges([en for _, en in sentences])\n",
    "    print(f\"Pre BPE size: {len(merges)}\")\n",
    "    merges = bpe(merges, [en for _, en in sentences[:CNT]], 1000)\n",
    "    merges_reversed = {i: seq for seq, i in merges.items()}\n",
    "EN_VOCAB_SIZE = len(merges)\n",
    "print(f\"Dict size: {len(merges)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b962a48-801a-4d87-a656-64eb918d8076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 9.887 seconds\n"
     ]
    }
   ],
   "source": [
    "with catchtime():\n",
    "    for jp, en in sentences[:CNT]:\n",
    "        assert (roundtripped := decode_en(encode_en(en, merges), merges_reversed)).startswith(\"BOS\" + en), f\"{roundtripped=} {en=}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c6f3fae-5e47-4f92-b3b9-d4e97f53191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now split up the data into train and validation sets\n",
    "TRAIN_SIZE = 10000\n",
    "n = int(0.9*TRAIN_SIZE) # first 90% will be train, rest val\n",
    "train_data = sentences[:n]\n",
    "val_data = sentences[n:TRAIN_SIZE]\n",
    "\n",
    "def tensorify(sentence_pairs, merges):\n",
    "    jp = [encode_jp(jp) for jp, _ in sentence_pairs]\n",
    "    en = [encode_en(en, merges) for _, en in sentence_pairs]\n",
    "    jp_t, en_t = torch.tensor(jp), torch.tensor(en)\n",
    "    Y_train = torch.zeros_like(en_t)\n",
    "    Y_train[:, :-1] = en_t[:, 1:]\n",
    "    Y_train[:, -1] = merges[EOS]\n",
    "    return jp_t, en_t, Y_train     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62eea708-c42d-48b2-9943-47057a98fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_iters = 200\n",
    "batch_size = 16\n",
    "\n",
    "def get_train_data():\n",
    "    pairs = []\n",
    "    for _ in range(batch_size):\n",
    "        ix = random.randint(0, len(train_data))\n",
    "        pairs.append(train_data[ix])\n",
    "    return pairs\n",
    "\n",
    "def get_batch(split, merges):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = get_train_data() if split == 'train' else val_data\n",
    "    return tensorify(data, merges)\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss_BROKEN(merges):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "Xjp_test, Xen_test, Y_test = get_batch('test', merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3ffd382-7d4f-418a-873e-20d3686fee1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.890109 M parameters\n"
     ]
    }
   ],
   "source": [
    "n_emb = 64\n",
    "n_heads = 4\n",
    "n_layer = 4\n",
    "learning_rate = 1e-3\n",
    "dropout = .1\n",
    "\n",
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, masked=True):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.key = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "        \n",
    "        self.masked = masked\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        query = self.query(x)\n",
    "        key = self.key(x)\n",
    "        value = self.value(x)\n",
    "        weight = query @ key.transpose(-2, -1) * C ** -.5\n",
    "\n",
    "        if self.masked:\n",
    "            weight = weight.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        weight = F.softmax(weight, dim=-1)\n",
    "        weight = self.dropout(weight)\n",
    "\n",
    "        return weight @ value\n",
    "\n",
    "class CrossHead(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.key = nn.Linear(n_emb, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_emb, head_size, bias=False)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x_dec, x_enc):\n",
    "        _, _, C = x_enc.shape\n",
    "        query = self.query(x_dec)\n",
    "        key = self.key(x_enc)\n",
    "        value = self.value(x_enc)\n",
    "        weight = query @ key.transpose(-2, -1) * C ** -.5\n",
    "\n",
    "        weight = F.softmax(weight, dim=-1)\n",
    "        weight = self.dropout(weight)\n",
    "\n",
    "        return weight @ value\n",
    "\n",
    "class MultiHead(nn.Module):\n",
    "    def __init__(self, num_heads, head_size, masked=True):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size, masked) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_emb, n_emb)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class MultiCrossHead(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([CrossHead(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_emb, n_emb)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x_dec, x_enc):\n",
    "        out = torch.cat([h(x_dec, x_enc) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FFBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(n_emb, 4*n_emb),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4*n_emb, n_emb),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "        assert n_emb % num_heads == 0, f\"num_heads should divide n_emb evenly, found {n_emb}%{num_heads} = {n_emb % num_heads}\"\n",
    "        head_size = n_emb // num_heads\n",
    "        self.att = MultiHead(num_heads, head_size)\n",
    "        self.cross_attn = MultiCrossHead(num_heads, head_size)\n",
    "        self.ff = FFBlock()\n",
    "        self.ln1 = nn.LayerNorm(n_emb)\n",
    "        self.ln2 = nn.LayerNorm(n_emb)\n",
    "        self.ln3 = nn.LayerNorm(n_emb)\n",
    "        \n",
    "    def forward(self, x, x_enc):\n",
    "        x = x + self.att(self.ln1(x))\n",
    "        x = x + self.cross_attn(self.ln2(x), x_enc)\n",
    "        x = x + self.ff(self.ln3(x))\n",
    "        return x\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, num_heads):\n",
    "        super().__init__()\n",
    "        assert n_emb % num_heads == 0, f\"num_heads should divide n_emb evenly, found {n_emb}%{num_heads} = {n_emb % num_heads}\"\n",
    "        head_size = n_emb // num_heads\n",
    "        self.att = MultiHead(num_heads, head_size, masked=False)\n",
    "        self.ff = FFBlock()\n",
    "        self.ln1 = nn.LayerNorm(n_emb)\n",
    "        self.ln2 = nn.LayerNorm(n_emb)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.att(self.ln1(x))\n",
    "        x = x + self.ff(self.ln2(x))\n",
    "        return x\n",
    "        \n",
    "\n",
    "class DecoderStack(nn.Module):\n",
    "    def __init__(self, num_stacks, num_heads):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([DecoderBlock(num_heads=num_heads) for _ in range(n_layer)])\n",
    "\n",
    "    def forward(self, x_dec, x_enc):\n",
    "        for layer in self.layers:\n",
    "            x_dec = layer(x_dec, x_enc)\n",
    "        return x_dec\n",
    "            \n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.enc_token_embedding_table = nn.Embedding(JP_VOCAB_SIZE, n_emb)\n",
    "        self.enc_position_embedding_table = nn.Embedding(block_size, n_emb)\n",
    "        self.dec_token_embedding_table = nn.Embedding(EN_VOCAB_SIZE, n_emb)\n",
    "        self.dec_position_embedding_table = nn.Embedding(block_size, n_emb)\n",
    "        self.decoder_blocks = DecoderStack(n_layer, n_heads)\n",
    "        self.encoder_blocks = nn.Sequential(*[EncoderBlock(num_heads=n_heads) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_emb) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_emb, EN_VOCAB_SIZE)\n",
    "\n",
    "    def forward(self, enc_idx, dec_idx, targets=None):\n",
    "        B, T_enc = enc_idx.shape\n",
    "        _, T_dec = dec_idx.shape\n",
    "\n",
    "        # both (B,T_enc) tensor of integers\n",
    "        enc_tok_emb = self.enc_token_embedding_table(enc_idx) # (B,T_enc,C)\n",
    "        enc_pos_emb = self.enc_position_embedding_table(torch.arange(T_enc, device=device)) # (T_enc,C)\n",
    "\n",
    "        x_enc = enc_tok_emb + enc_pos_emb\n",
    "\n",
    "        y_enc = self.encoder_blocks(x_enc)\n",
    "\n",
    "        dec_tok_emb = self.dec_token_embedding_table(dec_idx) # (B,T_dec,C)\n",
    "        dec_pos_emb = self.dec_position_embedding_table(torch.arange(T_dec, device=device)) # (T_dec,C)\n",
    "\n",
    "        x_dec = dec_tok_emb + dec_pos_emb # (B,T_dec,C)\n",
    "        # HERE: x_enc -> y_enc\n",
    "        x = self.decoder_blocks.forward(x_dec, y_enc) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n",
    "model = Model()\n",
    "m = model.to(device)\n",
    "# print the number of parameters in the model\n",
    "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "losses=[]\n",
    "test_losses=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f29953-b7f6-4f6e-91c9-47bc8cb95265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 elapsed 2s: train: 6.9057\n"
     ]
    }
   ],
   "source": [
    "eval_interval = 300\n",
    "max_iters = 1000\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    Xjp_b, Xen_b, Y_b = get_batch('train', merges)\n",
    "    logits, loss = m(Xjp_b, Xen_b, Y_b)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    losses.append(loss.item())\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        #_, test_loss = m(Xjp_test, Xen_test, Y_test)\n",
    "        #test_losses.append(test_loss.item())\n",
    "        #print(f\"step {iter} elapsed {time.time() - start:.0f}s: train: {loss.item():.4f} test: {test_loss.item():.4f}\")\n",
    "        test_losses.append(loss.item())\n",
    "        print(f\"step {iter} elapsed {time.time() - start:.0f}s: train: {loss.item():.4f}\")\n",
    "    else:\n",
    "        test_losses.append(test_losses[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4699972-193b-4987-918a-d3d8f92ec0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.plot(test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c303f6c3-b436-4c69-8b33-0e9650329730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input=\"何かしてみましょう。\"\n",
      "translated=\"BOSLet's try something.EOS\"\n",
      "expected=\"Let's try something.\"\n"
     ]
    }
   ],
   "source": [
    "def generate_response(jp, merges):\n",
    "    assert jp.shape[0] == 1\n",
    "    idx = torch.zeros((1,1), dtype=torch.long)\n",
    "    idx += merges[BOS]\n",
    "    # idx is (B, T) array of indices in the current context\n",
    "    for _ in range(block_size):\n",
    "        # crop idx to the last block_size tokens\n",
    "        idx_cond = idx[:, -block_size:]\n",
    "        # get the predictions\n",
    "        logits, loss = model(jp, idx_cond)\n",
    "        # focus only on the last time step\n",
    "        logits = logits[:, -1, :] # becomes (B, C)\n",
    "        # apply softmax to get probabilities\n",
    "        probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "        # sample from the distribution\n",
    "        idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "        # append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        if idx_next[0][0].item() == merges[EOS]:\n",
    "            break\n",
    "\n",
    "    return idx\n",
    "\n",
    "def translate(jp, expected=None):\n",
    "    encoded_jp = encode_jp(jp)\n",
    "    translated = decode_en(generate_response(torch.tensor([encoded_jp]), merges).tolist()[0], merges)\n",
    "    s = f\"input=\\\"{jp}\\\"\\n{translated=}\\n\"\n",
    "    if expected:\n",
    "        s += f\"{expected=}\"\n",
    "    return s\n",
    "i = 1\n",
    "print(translate(sentences[i][0], sentences[i][1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
